<html>
<head>
	<meta content="text/html; charset=utf-8" http-equiv="Content-Type" />
	<title>Bowen Zhang</title>
	<meta content="Bowen Zhang, zbwglory.github.io" name="keywords" />
	<style media="screen" type="text/css">html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, font, img, ins, kbd, q, s, samp, small, strike, strong, sub, tt, var, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td {
  border: 0pt none;
  font-family: Arial, Helvetica, sans-serif;
  font-size: 100%;
  font-style: normal;
  font-weight: inherit;
  margin: 0pt;
  outline-color: invert;
  outline-style: none;
  outline-width: 0pt;
  padding: 0pt;
  vertical-align: baseline;
}

a {
  color: #1772d0;
  text-decoration:none;
}

a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
}

a.paper {
  font-weight: bold;
  font-size: 12pt;
}

b.paper {
  font-weight: bold;
  font-size: 12pt;
}

* {
  margin: 0pt;
  padding: 0pt;
}

body {
  position: relative;
  margin: 3em auto 2em auto;
  width: 800px;
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 14px;
  background: #eee;
}

h2 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 15pt;
  font-weight: 700;
}

h3 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 16px;
  font-weight: 700;
}

strong {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 13px;
  font-weight:bold;
}

ul {
  list-style: circle;
}

img {
  border: none;
}

li {
  padding-bottom: 0.5em;
  margin-left: 1.4em;
}

alert {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 13px;
  font-weight: bold;
  color: #FF0000;
}

em, i {
	font-style:italic;
}

div.section {
  clear: both;
  margin-bottom: 1.5em;
  background: #eee;
}

div.spanner {
  clear: both;
}

div.paper {
  clear: both;
  margin-top: 0.5em;
  margin-bottom: 1em;
  border: 1px solid #ddd;
  background: #fff;
  padding: 1em 1em 1em 1em;
}

div.paper div {
  padding-left: 230px;
}

img.paper {
  margin-bottom: 0.5em;
  float: left;
  width: 200px;
}

span.blurb {
  font-style:italic;
  display:block;
  margin-top:0.75em;
  margin-bottom:0.5em;
}

pre, code {
  font-family: 'Lucida Console', 'Andale Mono', 'Courier', monospaced;
  margin: 1em 0;
  padding: 0;
}

div.paper pre {
  font-size: 0.9em;
}
</style>

<link href="http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css" /><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans+Condensed:300' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz' rel='stylesheet' type='text/css'>-->
</head>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-45959174-3', 'zbwglory.github.io');
  ga('send', 'pageview');

</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-66888300-1', 'auto');
  ga('send', 'pageview');

</script>
<body>
<div style="margin-bottom: 1em; border: 1px solid #ddd; background-color: #fff; padding: 1em; height: 140px;">
<div style="margin: 0px auto; width: 100%;">
<img title="Bowen Zhang" style="float: left; padding-left: .01em; height: 140px;" src="photo/Selfie.png" />
<div style="padding-left: 10em; vertical-align: top; height: 120px;"><span style="line-height: 150%; font-size: 20pt;">Bowen Zhang</span><br />
<span><strong>PhD student</strong></span><br />
<span><a href='http://www.teds.usc.edu'>Theoretical & Empirical Data Science (TEDS) Lab</a></span> <br />
<span><a href='https://www.usc.edu'>University of Southern California</a></span><br />
<span><strong>Email  </strong>:zbwglory [at] gmail.com</span> <br />
</div>
</div>
</div>
<!--<div style="clear: both; background-color: #fff; margin-top: 1.5em; padding: .2em; padding-left: .3em;">-->

<div style="clear: both;">
<div class="section">
<h2>About Me (<a href='cv_bwzhang_usc.pdf'>Resume</a>)</h2>
<div class="paper">
	I am a PhD student with Prof. <a href='http://www-bcf.usc.edu/~feisha/'>Fei Sha</a> at <a href='https://www.usc.edu'>University of Southern California</a>.
	<br> <br>
	I obtained my M.Eng. and B.Eng. degree from <a href='http://en.tongji.edu.cn'> Tongji University</a> working with Prof. <a href='https://scholar.google.com/citations?user=WioFu64AAAAJ&hl=en'>Hanli Wang</a>. I was a visiting student at <a href='http://english.siat.cas.cn/'>Shenzhen Institute of Advanced Technology</a> with Prof. <a href='https://scholar.google.com/citations?user=gFtI-8QAAAAJ&hl=en'>Yu Qiao</a>.
	<br> <br>
	I was an intern at Google Research, Amazon AWS Rekognition, and Tencent AI lab at Seattle.
</div>
</div>
</div>

<div style="clear: both;">
<div class="section">
  <h2>News</h2>
  <div class="paper">
    <ul>
	  <li> Nov. 19, 2020  : Two new video understanding papers are on arXiv. </li>
	  <li> Oct. 5, 2020  : One paper has been accepted by EMNLP 2020. </li>
	  <li> Apr. 22, 2019  : ECCV 2018's <a href='https://github.com/zbwglory/CMHSE'>code</a> is released. </li>
		<li>  Aug. 14, 2018  : One paper has been accepted by EMNLP 2018. </li>
		<li>  Aug. 14, 2018  : One paper has been accepted by ECCV 2018. </li>
		<li> Jan. 9, 2018: The extension of CVPR'16 paper is accepted by IEEE TIP. </li>
    </ul>
  </div>
</div>
</div>

<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Recent Publications (<a href='publication.html'>Full List</a>) (<a href='https://scholar.google.com/citations?user=nI3cKV8AAAAJ&hl=en'>Google Scholar</a>)</h2>

<div class="paper" id="hammer_arxiv">
<strong>A Hierarchical Multi-Modal Encoder for Moment Localization in Video Corpus</strong><br />
<strong>Bowen Zhang*</strong>, Hexiang Hu*, Joonseok Lee, Ming Zhao, Sheide Chammas, Vihan Jain, Eugene Ie, and Fei Sha <br />
arXiv, 2020. <br />
[ <a href='https://arxiv.org/pdf/2011.09046.pdf'>Paper</a> ] [Code]  <br />
</div>
<div class="spanner"></div>
</div>

<div class="paper" id="odas_arxiv">
<strong>Online Action Detection in Streaming Videos with Time Buffers</strong><br />
<strong>Bowen Zhang</strong>, Hao Chen, Meng Wang, and Yuanjun Xiong<br />
arXiv, 2020. <br />
[ <a href='https://arxiv.org/pdf/2010.03016.pdf'>Paper</a> ]  <br />
</div>
<div class="spanner"></div>
</div>

<div class="paper" id="emnlp20">
<strong>Learning to Represent Image and Text with Denotation Graph</strong><br />
<strong>Bowen Zhang</strong>, Hexiang Hu, Vihan Jain, Eugene Ie, and Fei Sha <br />
Conference on Empirical Methods in Natural Language Processing (<strong>EMNLP</strong>), 2020. <br />
[ <a href='https://arxiv.org/pdf/2010.02949.pdf'>Paper</a> ] [Code]  <br />
</div>
<div class="spanner"></div>
</div>

<div class="paper" id="iccv_ws_storytelling">
<strong>Visual Storytelling via Predicting Anchor Word Embeddings in the Stories</strong><br />
<strong>Bowen Zhang</strong>, Hexiang Hu, and Fei Sha <br />
ICCV 2019 Workshop on Closing the Loop Between Vision and Language, 2019. <br />
[ <a href='papers/ICCV2019_WS_ZhangHF.pdf'>Paper</a> ]  <br />
</div>
<div class="spanner"></div>
</div>

<div class="paper" id="arxiv_topic">
<strong>Topic Augmented Generator for Abstractive Summarization </strong><br />
Melissa Ailem, <strong>Bowen Zhang</strong>, and Fei Sha <br />
arxiv 1908.07026 (Short version is on BayLearn 2019). <br />
[ <a href='https://arxiv.org/pdf/1908.07026.pdf'>Paper</a> ]  <br />
</div>
<div class="spanner"></div>
</div>


<div class="paper" id="emnlp">
<strong>A Probabilistic Model for Joint Learning of Word Embeddings from Texts and Images</strong><br />
Melissa Ailem, <strong>Bowen Zhang</strong>, Aurélien Bellet, Pascal Denis, and Fei Sha <br />
Conference on Empirical Methods in Natural Language Processing (<strong>EMNLP</strong>), 2018. <br />
[ <a href='http://researchers.lille.inria.fr/abellet/papers/emnlp18.pdf'>Paper</a> ]  <br />
</div>
<div class="spanner"></div>
</div>


<div class="paper" id="eccv_CHAE">
<strong>Cross-Modal and Hierarchical Modeling of Video and Text</strong><br />
<strong>Bowen Zhang*</strong>, Hexiang Hu*, and Fei Sha <br />
European Conference on Computer Vision (<strong>ECCV</strong>), 2018. <br />
[ <a href='CMHSE/0528.pdf'>Paper</a>  ] [<a href='CMHSE/index.html'>Project page</a>] [<a href='https://github.com/zbwglory/CMHSE'>Code</a>]<br />
</div>
<div class="spanner"></div>
</div>


<div class="paper" id="tip_DTMV">
<strong>Real-Time Action Recognition with Deeply-Transferred Motion Vector CNNs</strong><br />
<strong>Bowen Zhang</strong>, Limin Wang, Zhe Wang, Yu Qiao and Hanli Wang <br />
IEEE Transaction on Image Processing (<strong>TIP</strong>), 2018. (<alert>Extension of CVPR'16</alert>) <br />
[ <a href='papers/08249882.pdf'>Paper</a> ]  <br />
</div>
<div class="spanner"></div>
</div>

<div class="paper" id="CVPR16">
<strong>Real-time Action Recognition with Enhanced Motion Vector CNNs</strong><br />
<strong>Bowen Zhang</strong>, Limin Wang, Zhe Wang, Yu Qiao, and Hanli Wang <br />
IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2016. <br />
<alert>Real-time action recogntion with high performance.</alert> <br />
[ <a href='papers/CVPR2016_ZhangWWQW.pdf'>Paper</a> ]  [ <a href='MV-CNN/index.html'>Project page</a> ] <br />
<div class="spanner"></div>
</div>

</div>
</div>



<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Competitions</h2>
<div class="paper">
<ul>
<li><strong><a href='http://activity-net.org/challenges/2017/evaluation.html'>The ActivityNet Challenge 2017 at CVPR'17:</a> Untrimmed, Rank</strong>: 2/32, <strong> Trimmed, Rank</strong>: 2/22, <strong> Localization, Rank</strong>: 2/13</li>
<li><strong><a href='http://activity-net.org/challenges/2016/program.html#'>The ActivityNet Challenge 2016 at CVPR'16:</a> Untrimmed Video Classification</strong>,  <strong>Rank</strong>: 1/24</li>
<li><strong><a href='http://lsun.cs.princeton.edu/2016/#schedule'>The LSUN Challenge 2016 at CVPR'16:</a> Scene Classification</strong>,  <strong>Rank</strong>: 1</li>
<li><strong><a href='http://www.multimediaeval.org/mediaeval2015/affectiveimpact2015/'>The 2015 Affective Impact of Movies Task:</a> Violence Task, Rank: </strong> 2/10, <strong>  Valence Task, Rank: </strong> 2/8, <strong> Arousal Task, Rank: </strong> 1/8 </li>
<li><strong><a href='http://www.multimediaeval.org/mediaeval2014/violence2014/'>The 2014 Affect in Multimedia Task:</a> Main Task</a></strong>,  <strong>Rank</strong>: 4/8, <strong>Generalization Task, Rank</strong>: 4/6</li>

</ul>
<div class="spanner"></div>
</div>
</div>
</div>

<div style="clear:both;">
<p align="right"><font size="5">Last Updated on Oct. 2020</a></font></p>
<p align="right"><font size="5">Published with <a href='https://pages.github.com/'>GitHub Pages</a></font></p>
</div>

<hr>
</body>
</html>
